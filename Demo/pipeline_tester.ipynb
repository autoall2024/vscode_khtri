{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import great_expectations as ge\n",
    "from ctgan import CTGAN, load_demo\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline\n",
    "# Step 1: Load real dataset\n",
    "def get_real_dataset():\n",
    "    df = load_demo()\n",
    "    return df\n",
    "\n",
    "# Step 2: Train CTGAN and generate synthetic data\n",
    "def train_ctgan(df, target_col, epochs=10):\n",
    "    discrete_cols = [col for col in df.columns if col != target_col and df[col].dtype == 'object']\n",
    "    ctgan = CTGAN(epochs=epochs)\n",
    "    ctgan.fit(df.drop(columns=[target_col]), discrete_cols)\n",
    "    return ctgan\n",
    "\n",
    "def generate_synthetic_data(ctgan_model, num_rows=1000):\n",
    "    return ctgan_model.sample(num_rows)\n",
    "\n",
    "# Step 3: Detect and remove anomalies\n",
    "def detect_anomalies(df, contamination=0.05, target_col='income'):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    for col in df_copy.columns:\n",
    "        if df_copy[col].dtype == 'object' or df_copy[col].dtype.name == 'category':\n",
    "            le = LabelEncoder()\n",
    "            df_copy[col] = le.fit_transform(df_copy[col].astype(str))\n",
    "\n",
    "    # Fit IsolationForest on feature columns only\n",
    "    clf = IForest(contamination=contamination)\n",
    "    clf.fit(df_copy.drop(columns=[target_col]).values)\n",
    "    \n",
    "    # Return the cleaned dataset with anomalies removed\n",
    "    mask_normal = (clf.labels_ == 0)\n",
    "    return df[mask_normal].copy()\n",
    "\n",
    "# Step 4: Validate data using Great Expectations\n",
    "def validate_data(df, target_col):\n",
    "    ge_df = ge.from_pandas(df)\n",
    "    ge_df.expect_column_values_to_not_be_null(target_col)\n",
    "    ge_df.expect_column_values_to_be_in_set(target_col, df[target_col].unique())\n",
    "    result = ge_df.validate()\n",
    "    return result\n",
    "\n",
    "# Step 5: Train and evaluate a classifier\n",
    "# Using LabelEncoder\n",
    "def train_and_evaluate(df, target_col):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Label Encode categorical columns\n",
    "    for col in df_copy.columns:\n",
    "        if df_copy[col].dtype == 'object' or df_copy[col].dtype.name == 'category':\n",
    "            le = LabelEncoder()\n",
    "            df_copy[col] = le.fit_transform(df_copy[col].astype(str))\n",
    "    \n",
    "    # Split features and target\n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "    return accuracy\n",
    "\n",
    "# Using OneHotEncoder\n",
    "# def train_and_evaluate(df, target_col):\n",
    "#     # One-Hot Encode categorical columns\n",
    "#     df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "#     # print(df_encoded.columns)\n",
    "    \n",
    "#     # Find the new target column after one-hot encoding\n",
    "#     new_target_col = [col for col in df_encoded.columns if col.startswith(target_col)][0]  # Example: 'income_>50K'\n",
    "    \n",
    "#     # Split features and target\n",
    "#     X = df_encoded.drop(columns=[new_target_col])\n",
    "#     y = df_encoded[new_target_col]\n",
    "    \n",
    "#     # Train-test split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Train the model\n",
    "#     clf = RandomForestClassifier()\n",
    "#     clf.fit(X_train, y_train)\n",
    "    \n",
    "#     # Evaluate accuracy\n",
    "#     accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Pipeline Execution\n",
    "print(\"==== Starting Pipeline... ====\")\n",
    "\n",
    "# Step 1: Load dataset\n",
    "print(\"Step 1: Loading real dataset...\")\n",
    "df_real = get_real_dataset()\n",
    "print(f\"Real dataset shape: {df_real.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train CTGAN and generate synthetic data\n",
    "print(\"Step 2: Training CTGAN and generating synthetic data...\")\n",
    "ctgan_model = train_ctgan(df_real, target_col='income', epochs=50)\n",
    "df_synthetic = generate_synthetic_data(ctgan_model, num_rows=1000)\n",
    "print(f\"Synthetic dataset shape: {df_synthetic.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Detect and remove anomalies\n",
    "print(\"Step 3: Detecting anomalies...\")\n",
    "df_synthetic['income'] = np.random.choice(df_real['income'].unique(), size=len(df_synthetic))  # Ensure target column is present\n",
    "df_cleaned = detect_anomalies(df_synthetic, contamination=0.05, target_col='income')\n",
    "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")\n",
    "# print(df_cleaned['income'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Validate data\n",
    "print(\"Step 4: Validating data...\")\n",
    "validation_result = validate_data(df_cleaned, target_col='income')\n",
    "if validation_result.success:\n",
    "    print(\"Data validation passed.\")\n",
    "else:\n",
    "    print(\"Data validation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train and evaluate model\n",
    "print(\"Step 5: Training and evaluating model...\")\n",
    "accuracy = train_and_evaluate(df_cleaned, target_col='income')\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")\n",
    "print(\"==== Pipeline Completed. ====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data Comparation\n",
    "# for mean, variance, and standard deviation for each numeric column\n",
    "def calculate_statistics(df, label):\n",
    "    \"\"\"Calculate mean, variance, and standard deviation for each numeric column.\"\"\"\n",
    "    # Select only numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    stats = pd.DataFrame({\n",
    "        'Mean': numeric_cols.mean(),\n",
    "        'Variance': numeric_cols.var(),\n",
    "        'Standard Deviation': numeric_cols.std()\n",
    "    })\n",
    "    stats['Dataset'] = label\n",
    "\n",
    "    print(\"Statistics Calculation Results:\")\n",
    "    print(stats.head())\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_metric_comparison(real_stats, synthetic_stats, cleaned_stats, metric):\n",
    "    \"\"\"Plot a separate bar chart for a specific metric (Mean, Variance, or Standard Deviation).\"\"\"\n",
    "    # Combine statistics for the specified metric\n",
    "    stats = pd.concat([\n",
    "        real_stats[['Mean', 'Variance', 'Standard Deviation', 'Dataset']].assign(Metric=metric),\n",
    "        synthetic_stats[['Mean', 'Variance', 'Standard Deviation', 'Dataset']].assign(Metric=metric),\n",
    "        cleaned_stats[['Mean', 'Variance', 'Standard Deviation', 'Dataset']].assign(Metric=metric)\n",
    "    ]).reset_index().rename(columns={\"index\": \"Feature\"})\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.barplot(data=stats, x='Feature', y=metric, hue='Dataset', ci=None)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Comparison of {metric}')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(title='Dataset')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# def plot_statistics(real_stats, synthetic_stats, cleaned_stats):\n",
    "#     \"\"\"Plot mean, variance, and standard deviation comparisons.\"\"\"\n",
    "#     stats = pd.concat([real_stats, synthetic_stats, cleaned_stats])\n",
    "#     stats = stats.reset_index().melt(id_vars=['index', 'Dataset'], var_name='Metric', value_name='Value')\n",
    "    \n",
    "#     plt.figure(figsize=(15, 6))\n",
    "#     sns.barplot(data=stats, x='index', y='Value', hue='Dataset', ci=None)\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.title('Comparison of Mean, Variance, and Standard Deviation')\n",
    "#     plt.xlabel('Features')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.legend(title='Dataset')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "def plot_statistics(real_stats, synthetic_stats, cleaned_stats):\n",
    "    \"\"\"Plot mean, variance, and standard deviation as separate figures.\"\"\"\n",
    "    print(\"Plotting Mean Comparison...\")\n",
    "    plot_metric_comparison(real_stats, synthetic_stats, cleaned_stats, 'Mean')\n",
    "\n",
    "    print(\"Plotting Variance Comparison...\")\n",
    "    plot_metric_comparison(real_stats, synthetic_stats, cleaned_stats, 'Variance')\n",
    "\n",
    "    print(\"Plotting Standard Deviation Comparison...\")\n",
    "    plot_metric_comparison(real_stats, synthetic_stats, cleaned_stats, 'Standard Deviation')\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(df, title):\n",
    "    \"\"\"Plot a heatmap of the correlation matrix for a dataset.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "    corr = numeric_cols.corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "    plt.title(f'Correlation Heatmap - {title}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions \n",
    "# for both numerical and categorical columns for the real, synthetic, and cleaned datasets\n",
    "def plot_numerical_distribution(df_real, df_synthetic, df_cleaned, column):\n",
    "    \"\"\"Plot the distribution of a numerical column for real, synthetic, and cleaned datasets.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df_real[column], label='Real Data', kde=True, color='blue', stat='density', alpha=0.5)\n",
    "    sns.histplot(df_synthetic[column], label='Synthetic Data', kde=True, color='green', stat='density', alpha=0.5)\n",
    "    sns.histplot(df_cleaned[column], label='Cleaned Data', kde=True, color='red', stat='density', alpha=0.5)\n",
    "    \n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_categorical_distribution(df_real, df_synthetic, df_cleaned, column):\n",
    "    \"\"\"Plot the distribution of a categorical column for real, synthetic, and cleaned datasets.\"\"\"\n",
    "    real_counts = df_real[column].value_counts(normalize=True)\n",
    "    synthetic_counts = df_synthetic[column].value_counts(normalize=True)\n",
    "    cleaned_counts = df_cleaned[column].value_counts(normalize=True)\n",
    "\n",
    "    combined_counts = pd.DataFrame({\n",
    "        'Real Data': real_counts,\n",
    "        'Synthetic Data': synthetic_counts,\n",
    "        'Cleaned Data': cleaned_counts\n",
    "    }).fillna(0)\n",
    "\n",
    "    combined_counts.plot(kind='bar', figsize=(12, 6))\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main visualization script\n",
    "def visualize_comparison(df_real, df_synthetic, df_cleaned):\n",
    "    # Calculate statistics for each dataset\n",
    "    print(\"Calculating statistics...\")\n",
    "    real_stats = calculate_statistics(df_real, label='Real Data')\n",
    "    synthetic_stats = calculate_statistics(df_synthetic, label='Synthetic Data')\n",
    "    cleaned_stats = calculate_statistics(df_cleaned, label='Cleaned Data')\n",
    "    print(\"Calculating statistics done.\")\n",
    "    \n",
    "    # Plot statistics comparison\n",
    "    print(\"Plotting statistics comparison...\")\n",
    "    plot_statistics(real_stats, synthetic_stats, cleaned_stats)\n",
    "    print(\"Plotting statistics comparison done.\")\n",
    "\n",
    "    # Plot correlation heatmaps for each dataset\n",
    "    print(\"Plotting correlation heatmaps...\")\n",
    "    plot_correlation_heatmap(df_real, 'Real Data')\n",
    "    plot_correlation_heatmap(df_synthetic, 'Synthetic Data')\n",
    "    plot_correlation_heatmap(df_cleaned, 'Cleaned Data')\n",
    "    print(\"Plotting correlation heatmaps done.\")\n",
    "\n",
    "\n",
    "def visualize_distributions(df_real, df_synthetic, df_cleaned):\n",
    "    \"\"\"Visualize distributions for both numerical and categorical columns.\"\"\"\n",
    "    numeric_columns = df_real.select_dtypes(include=[np.number]).columns\n",
    "    categorical_columns = df_real.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    print(\"Visualizing numerical distributions...\")\n",
    "    for column in numeric_columns:\n",
    "        plot_numerical_distribution(df_real, df_synthetic, df_cleaned, column)\n",
    "    print(\"Visualizing numerical distributions done.\")\n",
    "    \n",
    "    print(\"Visualizing categorical distributions...\")\n",
    "    for column in categorical_columns:\n",
    "        plot_categorical_distribution(df_real, df_synthetic, df_cleaned, column)\n",
    "    print(\"Visualizing categorical distributions done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== Starting Post-pipeline Data Visualization.... ====\")\n",
    "# Visualize data to check and compare whether the metrics \n",
    "# such as mean, variance, deviation and correlation\n",
    "# of the real data, synthetic/augmented data and cleaned data are closely match or not\n",
    "\n",
    "# Export data to .csv files\n",
    "print(\"1. Exporting data to CSV files...\")\n",
    "df_real.to_csv(\"real_data.csv\", index=False)\n",
    "df_synthetic.to_csv(\"synthetic_data.csv\", index=False)\n",
    "df_cleaned.to_csv(\"clean_data.csv\", index=False)\n",
    "print(\"Real and synthetic data saved successfully.\")\n",
    "\n",
    "# Visualize Data\n",
    "print(\"2. Visualizing Data...\")\n",
    "visualize_comparison(df_real, df_synthetic, df_cleaned)\n",
    "visualize_distributions(df_real, df_synthetic, df_cleaned)\n",
    "print(\"Visualizing Data completed.\")\n",
    "\n",
    "print(\"==== Post-pipeline Data Visualization Completed. ====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
